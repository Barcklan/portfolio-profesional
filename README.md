# ğŸ’¼ Portafolio Profesional

<table>
<tr>
<td width="150" align="center">

<img src="https://github.com/barcklan.png" width="120" style="border-radius: 50%; margin-right: 20px;">

</td>
<td>

## ğŸ‘‹ Sobre mÃ­

Soy un profesional apasionado por el **anÃ¡lisis de datos**, la **modelaciÃ³n estadÃ­stica** y el **desarrollo de soluciones basadas en Machine Learning** que contribuyan a la toma de decisiones informadas.

**Nombre:** Claudio AndrÃ©s DÃ­az Vargas  
**EspecializaciÃ³n:** Ingeniero en EstadÃ­stica, especializado en Machine Learning y Ciencia de Datos  
**Correo:** [cdiazv.ies@gmail.com](mailto:cdiazv.ies@gmail.com)  
**GitHub:** [https://github.com/barcklan](https://github.com/barcklan)

Tengo experiencia en **anÃ¡lisis exploratorio de datos**, **modelado estadÃ­stico**, **tÃ©cnicas de aprendizaje supervisado y no supervisado**, **optimizaciÃ³n de modelos**, **visualizaciÃ³n de datos** y **automatizaciÃ³n de procesos analÃ­ticos** con Python.

Mi objetivo es **aplicar mis conocimientos en estadÃ­stica y Machine Learning** para diseÃ±ar soluciones basadas en datos que apoyen la toma de decisiones y generen impacto positivo.

</td>
</tr>
</table>

---

## ğŸš€ Proyectos Destacados

A continuaciÃ³n, se presentan tres de mis proyectos mÃ¡s relevantes, donde aplico conocimientos en anÃ¡lisis, programaciÃ³n y documentaciÃ³n tÃ©cnica.

---

## ğŸ§  Proyecto 1 â€” Sistema Inteligente de Scoring Crediticio (DNN)

> **EvaluaciÃ³n Modular - MÃ³dulo 7**  
> **Tema:** Redes Neuronales Profundas aplicadas a riesgo crediticio.

---

### ğŸ¯ Objetivo
DiseÃ±ar, entrenar y evaluar un modelo de red neuronal profunda para predecir la probabilidad de impago de clientes bancarios, utilizando un conjunto de datos realista.  
El modelo debe ser explicable, eficiente y presentar resultados interpretables para su uso en contextos financieros.

---

### ğŸ§© Contexto
Las entidades financieras deben decidir si otorgan o no un crÃ©dito a un cliente. Esta decisiÃ³n, si se basa en modelos poco explicables, puede generar sesgos, exclusiones injustas o pÃ©rdidas econÃ³micas.  
Este proyecto busca construir un modelo **moderno, preciso y explicable**, basado en **redes neuronales profundas (DNN)**, que permita mejorar las decisiones crediticias.

---

### ğŸ“Š Resumen
Se desarrollÃ³ un sistema de **scoring crediticio** basado en **redes neuronales profundas (DNN)** para predecir la probabilidad de impago.  
Tras aplicar **SMOTE** para balancear las clases, se entrenaron dos modelos:

- ğŸ§  **DNN simple** â†’ Accuracy: **70.5%**, AUC: **0.78**  
- âš™ï¸ **ResNet tabular** â†’ Accuracy: **64%**, AUC: **0.64**

ğŸ“ˆ La **DNN simple** mostrÃ³ mejor generalizaciÃ³n, equilibrio y estabilidad, siendo la opciÃ³n mÃ¡s confiable para decisiones crediticias.

---

### ğŸ§° TecnologÃ­as Utilizadas
- Python  
- TensorFlow / Keras  
- Scikit-learn  
- Pandas / NumPy  
- Matplotlib / Seaborn  
- SMOTE (imbalanced-learn)

---

### âœï¸ Autor
**Claudio AndrÃ©s DÃ­az Vargas**

ğŸ”— [Ver proyecto completo Â»](./proyecto1)

---

<hr style="border:1px solid #bbb; margin:40px 0;">

---

## ğŸ¥ Proyecto 2 â€” ClasificaciÃ³n de Notas ClÃ­nicas con Enfoque Ã‰tico y MitigaciÃ³n de Sesgos

> **EvaluaciÃ³n Modular - MÃ³dulo 8**  
> **Tema:** Procesamiento de Lenguaje Natural (NLP) aplicado al Ã¡mbito clÃ­nico.

---

### ğŸ¯ Objetivo
Desarrollar un sistema de **NLP** que clasifique textos mÃ©dicos segÃºn su **gravedad clÃ­nica (leve, moderado, severo)**, aplicando buenas prÃ¡cticas de **preprocesamiento, evaluaciÃ³n y mitigaciÃ³n de sesgos** lingÃ¼Ã­sticos y sociales.

---

### ğŸ§© Contexto
Los registros mÃ©dicos en texto libre contienen informaciÃ³n valiosa, pero requieren tiempo y experiencia para analizarse manualmente.  
Este proyecto propone un **sistema automatizado** que asista en la **detecciÃ³n temprana de afecciones**, priorizando pacientes y reduciendo riesgos.

TambiÃ©n se analiza la **Ã©tica del modelo**, considerando sesgos lingÃ¼Ã­sticos o sociales, y se incorporan **mÃ©todos de interpretabilidad (LIME)** para fortalecer la transparencia del sistema.

---

### ğŸ“Š Resumen
Se compararon dos enfoques:

- ğŸ“š **Naive Bayes + TF-IDF**  
- ğŸ¤– **BERT Multilingual / BETO**

Ambos lograron **mÃ©tricas perfectas en validaciÃ³n**, revelando gran capacidad predictiva pero riesgo de **sobreajuste**.  
Se aplicaron tÃ©cnicas de **interpretabilidad (LIME)** y una evaluaciÃ³n Ã©tica sobre los posibles sesgos en el lenguaje clÃ­nico.

---

### ğŸ§° TecnologÃ­as Utilizadas
- Python  
- Scikit-learn  
- Transformers (Hugging Face)  
- BERT Multilingual / BETO  
- LIME  
- NLTK / spaCy  
- Pandas / NumPy

---

### âœï¸ Autor
**Claudio AndrÃ©s DÃ­az Vargas**

ğŸ”— [Ver proyecto completo Â»](./proyecto2)

---

<hr style="border:1px solid #bbb; margin:40px 0;">

---

## ğŸ” Proyecto 3 â€” Interpretabilidad de Modelos Predictivos usando LIME y SHAP

> **EvaluaciÃ³n Modular - MÃ³dulo 9**  
> **Tema:** Explicabilidad y Ã©tica en inteligencia artificial.

---

### ğŸ¯ Objetivo
Aplicar herramientas de **explicabilidad de modelos**, como **LIME** y **SHAP**, para analizar y justificar el comportamiento de un modelo de clasificaciÃ³n, destacando la importancia de la transparencia en la inteligencia artificial.

---

### ğŸ§© Contexto
Formar parte de un equipo que usa **IA en decisiones crÃ­ticas** implica construir modelos **explicables y Ã©ticamente responsables**.  
Este proyecto explora cÃ³mo la interpretabilidad permite **auditar la lÃ³gica interna** de los modelos y detectar errores o sesgos ocultos.

---

### ğŸ“Š Resumen
Se analizÃ³ un modelo de **Random Forest** para predecir **enfermedades cardÃ­acas**, utilizando **LIME** y **SHAP**.  
El modelo alcanzÃ³ **88.6% de precisiÃ³n**, pero las explicaciones revelaron **fallas crÃ­ticas**:

- Uso correcto de variables relevantes (**ECG**, **angina**, **frecuencia cardÃ­aca mÃ¡xima**).  
- **Manejo incorrecto del colesterol**: interpretÃ³ valores bajos como riesgosos y altos como protectores, debido a datos con valores `0.0`.

ğŸ“‰ Sin interpretabilidad, este error habrÃ­a pasado inadvertido, comprometiendo decisiones clÃ­nicas.  
El caso demuestra que **precisiÃ³n sin transparencia** no es suficiente: la interpretabilidad garantiza **auditorÃ­a, confianza y Ã©tica** en modelos de IA.

---

### ğŸ§° TecnologÃ­as Utilizadas
- Python  
- Scikit-learn  
- Random Forest  
- LIME  
- SHAP  
- Matplotlib / Seaborn  
- Pandas / NumPy

---

### âœï¸ Autor
**Claudio AndrÃ©s DÃ­az Vargas**

ğŸ”— [Ver proyecto completo Â»](./proyecto3)

---

<hr style="border:1px solid #bbb; margin:40px 0;">

---

## ğŸ§­ OrganizaciÃ³n y Buenas PrÃ¡cticas

Este portafolio estÃ¡ organizado de manera clara y estructurada:

- NavegaciÃ³n sencilla entre secciones  
- DocumentaciÃ³n tÃ©cnica y reflexiva  
- RedacciÃ³n cuidada, ortografÃ­a revisada y estilo profesional  

---
