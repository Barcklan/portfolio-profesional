# üß† Proyecto 1 ‚Äî Sistema Inteligente de Scoring Crediticio (DNN)

> **Tema:** Redes Neuronales Profundas aplicadas a riesgo crediticio

---

## üéØ Objetivo
Dise√±ar, entrenar y evaluar un modelo de red neuronal profunda (DNN) para predecir la probabilidad de impago de clientes bancarios, utilizando un conjunto de datos realista.  
El modelo debe ser explicable, eficiente y presentar resultados interpretables para su uso en contextos financieros.

---

## üß© Contexto
Las entidades financieras deben decidir si otorgan o no un cr√©dito a un cliente.  
Si la decisi√≥n se basa en modelos poco explicables, puede generar sesgos, exclusiones injustas o p√©rdidas econ√≥micas.  

Este proyecto busca construir un modelo **moderno, preciso y explicable**, basado en **redes neuronales profundas (DNN)**, que permita mejorar la calidad de las decisiones crediticias.

---

## üìä Resumen del Proyecto
- Se realiz√≥ un **an√°lisis exploratorio de datos (EDA)** para identificar patrones de buen/mal pagador.  
- Se aplic√≥ **preprocesamiento** y balanceo de clases con **SMOTE**.  
- Se entrenaron dos modelos principales:
  - üß† **DNN simple** ‚Üí Accuracy: 70.5%, AUC: 0.78  
  - ‚öôÔ∏è **ResNet tabular** ‚Üí Accuracy: 64%, AUC: 0.64  

üìà La **DNN simple** mostr√≥ mejor generalizaci√≥n y equilibrio, siendo la opci√≥n m√°s confiable.

---

## üß∞ Tecnolog√≠as Utilizadas
- Python  
- TensorFlow / Keras  
- Scikit-learn  
- Pandas / NumPy  
- Matplotlib / Seaborn  
- SMOTE (imbalanced-learn)

---

## üìÇ Estructura de Archivos

```bash
 proyecto1/                 ‚Üê Carpeta del Proyecto 1
   ‚îú‚îÄ üìú README.md              ‚Üê Documentaci√≥n detallada del proyecto 1
   ‚îú‚îÄ üìÇ data/                  ‚Üê (Opcional) datasets utilizados
   ‚îú‚îÄ üìî notebooks/             ‚Üê Notebooks de an√°lisis y entrenamiento
   ‚îú‚îÄ üìÇ scripts/               ‚Üê Scripts Python (.py) de entrenamiento, preprocesamiento, etc.
   ‚îú‚îÄ üìÇ reports/               ‚Üê Gr√°ficos, visualizaciones, resultados
   ‚îî‚îÄ üìú requirements.txt       ‚Üê Dependencias del proyecto
```
--- 

## > Resultados Principales/Hallazgos

Se desarroll√≥ un sistema de scoring crediticio basado en redes neuronales profundas para predecir la probabilidad de impago de clientes bancarios, comenzando con un an√°lisis exploratorio que identific√≥ diferencias entre buenos y malos pagadores, especialmente en monto y duraci√≥n del cr√©dito. Tras preprocesar los datos y aplicar SMOTE para balancear clases, se entrenaron dos modelos: una DNN simple y una ResNet tabular. 

<p align="center">
  <img src="img/DNN_Simple.png" width="43.6%" />
  <img src="img/RESNET.png" width="40%" />
</p>

<div align="center">
  
| M√©tricas  | Modelo DNN Simple | ResNet |
|-----------|-----------|-----------    |
| `Accuracy`|  0.705    |  0.640        |
|   `AUC`   |   0.780   |  0.640        |

</div>

Tal como se ve en las Curvas ROC, la DNN simple mostr√≥ un desempe√±o superior, con accuracy de 70,5% y AUC de 0,78, generalizando bien y equilibrando la predicci√≥n entre clientes ‚Äúgood‚Äù y ‚Äúbad‚Äù. En cambio, la ResNet obtuvo accuracy de 64% y AUC de 0,64, clasificando mejor a clientes ‚Äúbad‚Äù pero con un riesgo elevado de falsos positivos. En conclusi√≥n, la DNN simple se posiciona como la opci√≥n m√°s confiable y efectiva para decisiones de cr√©dito, aunque a√∫n puede mejorarse la predicci√≥n de clientes solventes y la interpretabilidad del modelo.

## > üìÑ Conclusiones

>El sistema de scoring crediticio basado en redes neuronales profundas compar√≥ una DNN simple y una ResNet tabular.
>
>La DNN obtuvo mejor desempe√±o (Accuracy ‚âà 70%, AUC ‚âà 0.78), mostrando buena capacidad de generalizaci√≥n y discriminaci√≥n entre clientes buenos y >malos, mientras que la ResNet fue menos precisa (Accuracy ‚âà 64%, AUC ‚âà 0.64) y gener√≥ m√°s falsos positivos, lo que implica mayor riesgo financiero.
>
>Aunque la DNN es el modelo m√°s confiable, presenta sesgo hacia la clase ‚ÄúBad‚Äù y baja precisi√≥n en clientes ‚ÄúGood‚Äù (43%).
>Se recomienda optimizar hiperpar√°metros, mejorar embeddings, ajustar el umbral de decisi√≥n y aplicar t√©cnicas de interpretabilidad (SHAP, LIME) >para garantizar transparencia y confiabilidad.

