# ğŸ¥ Proyecto 2 â€” ClasificaciÃ³n de Notas ClÃ­nicas con Enfoque Ã‰tico y MitigaciÃ³n de Sesgos

> ### Procesamiento de Lenguaje Natural (NLP) aplicado al Ã¡mbito clÃ­nico

---

## ğŸ¯ Objetivo
Desarrollar un sistema de **NLP** que clasifique textos mÃ©dicos segÃºn su **gravedad clÃ­nica (leve, moderado, severo)**, aplicando buenas prÃ¡cticas de **preprocesamiento, evaluaciÃ³n y mitigaciÃ³n de sesgos** lingÃ¼Ã­sticos y sociales.  
El modelo debe ser **transparente, explicable y Ã©ticamente responsable**.

---

## ğŸ§© Contexto
Los registros mÃ©dicos en texto libre contienen informaciÃ³n valiosa, pero requieren tiempo y conocimiento mÃ©dico para ser interpretados correctamente.  
El proyecto propone un **sistema automatizado** que ayuda a la **detecciÃ³n temprana de afecciones**, priorizando pacientes y reduciendo riesgos.

Se incluyen anÃ¡lisis de **posibles sesgos lingÃ¼Ã­sticos o sociales** y uso de **tÃ©cnicas de interpretabilidad (LIME)** para garantizar confianza y Ã©tica.

---

## ğŸ“Š Resumen del Proyecto
Se compararon dos enfoques:

- ğŸ“š **Naive Bayes + TF-IDF**  
- ğŸ¤– **BERT Multilingual / BETO**

Ambos lograron **mÃ©tricas perfectas en validaciÃ³n**, mostrando gran capacidad predictiva pero con riesgo de **sobreajuste**.  
Se aplicaron tÃ©cnicas de **interpretabilidad (LIME)** y evaluaciÃ³n Ã©tica sobre posibles sesgos en el lenguaje clÃ­nico.

ğŸ“ˆ El proyecto demuestra que los sistemas de NLP pueden aplicarse de manera **efectiva y responsable** en contextos clÃ­nicos.

---

## ğŸ§° TecnologÃ­as Utilizadas
- Python  
- Scikit-learn  
- Transformers (Hugging Face)  
- BERT Multilingual / BETO  
- LIME  
- NLTK / spaCy  
- Pandas / NumPy

---

## ğŸ“‚ Estructura de Archivos

```bash
 proyecto2/                 â† Carpeta del Proyecto 2
   â”œâ”€ ğŸ“œ README.md
   â”œâ”€ ğŸ“‚ data/
   â”œâ”€ ğŸ“” notebooks/
   â”œâ”€ ğŸ“‚ scripts/
   â”œâ”€ ğŸ“‚ reports/
   â””â”€ ğŸ“œ requirements.txt
```
--- 

## ğŸ“ˆ Resultados Principales/Hallazgos

Se implementaron y compararon dos enfoques: Naive Bayes con TF-IDF y BERT en espaÃ±ol, ambos entrenados en un dataset de notas clÃ­nicas. Los modelos alcanzaron mÃ©tricas perfectas en el conjunto de validaciÃ³n, lo que evidenciÃ³ tanto la capacidad de separaciÃ³n de los datos como el riesgo de sobreajuste. Para garantizar transparencia, se aplicaron mÃ©todos de interpretabilidad como LIME, y se evaluaron los riesgos Ã©ticos y sesgos potenciales.

<p align="center">
  <img src="img/Metricas.png" width="45.6%" />
  <img src="img/F1-Score.png" width="45%" />
</p>

<div align="center">

### Bayes Naives
  
| Gravedad ClÃ­nica | `accuracy`  | `precision` | `recall` | `F1-Score` |
|-----------|-----------|-----------|-----------|-----------|
| Leve| 1.00 | 1.00 | 1.00 | 1.00 |
| Moderado | 1.00 | 1.00 | 1.00 | 1.00 |
| Grave | 1.00 | 1.00 | 1.00 | 1.00 |

</div>

<div align="center">

### BERT
 
| Gravedad ClÃ­nica | `accuracy`  | `precision` | `recall` | `F1-Score` |
|-----------|-----------|-----------|-----------|-----------|
| Leve| 1.00 | 1.00 | 1.00 | 1.00 |
| Moderado | 1.00 | 1.00 | 1.00 | 1.00 |
| Grave | 1.00 | 1.00 | 1.00 | 1.00 |

</div>


Tanto Naive Bayes como BERT alcanzaron un rendimiento perfecto (100% en precisiÃ³n, recall, F1 y accuracy), lo que sugiere que el dataset es pequeÃ±o y fÃ¡cilmente separable, con posible sobreajuste. No se observa ventaja entre ambos modelos: Naive Bayes es mÃ¡s rÃ¡pido y eficiente para tareas simples, mientras que BERT ofrece mayor robustez para escenarios mÃ¡s complejos o con mayor volumen de datos.



## ğŸ“„ Conclusiones

El sistema de scoring crediticio basado en redes neuronales profundas comparÃ³ una DNN simple y una ResNet tabular.

La DNN obtuvo mejor desempeÃ±o (Accuracy â‰ˆ 70%, AUC â‰ˆ 0.78), mostrando buena capacidad de generalizaciÃ³n y discriminaciÃ³n entre clientes buenos y malos, mientras que la ResNet fue menos precisa (Accuracy â‰ˆ 64%, AUC â‰ˆ 0.64) y generÃ³ mÃ¡s falsos positivos, lo que implica mayor riesgo financiero.

Aunque la DNN es el modelo mÃ¡s confiable, presenta sesgo hacia la clase â€œBadâ€ y baja precisiÃ³n en clientes â€œGoodâ€ (43%).
Se recomienda optimizar hiperparÃ¡metros, mejorar embeddings, ajustar el umbral de decisiÃ³n y aplicar tÃ©cnicas de interpretabilidad (SHAP, LIME) para garantizar transparencia y confiabilidad.


#### ğŸ”— [Ver anÃ¡lisis completo en el Notebook (.ipynb) Â»](./notebooks/SISC_DNN.ipynb)
