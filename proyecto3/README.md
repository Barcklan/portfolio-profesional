# üîç Proyecto 3 ‚Äî Interpretabilidad de Modelos Predictivos usando LIME y SHAP

> ### Explicabilidad y √©tica en inteligencia artificial

---

## üéØ Objetivo
Aplicar herramientas de **explicabilidad de modelos**, como **LIME** y **SHAP**, para analizar y justificar el comportamiento de un modelo de clasificaci√≥n, destacando la importancia de la **transparencia y √©tica** en IA.

---

## üß© Contexto
Formar parte de un equipo que usa **IA en decisiones cr√≠ticas** implica construir modelos **explicables y auditables**.  
Este proyecto muestra c√≥mo la interpretabilidad permite **detectar errores y sesgos ocultos** y mejorar la confianza en las decisiones automatizadas.

---

## üìä Resumen del Proyecto
Se analiz√≥ un modelo de **Random Forest** para predecir **enfermedades card√≠acas**, utilizando **LIME** y **SHAP**:

- Precisi√≥n general: **88.6%**  
- Uso correcto de variables relevantes: **ECG, angina, frecuencia card√≠aca m√°xima**  
- Problema detectado: valores de **colesterol mal interpretados** (`0.0`), causando falsos positivos

üìà El proyecto demuestra que **precisi√≥n sin interpretabilidad** no es suficiente, y que la transparencia es esencial en IA cr√≠tica.

---

## üß∞ Tecnolog√≠as Utilizadas
- Python  
- Scikit-learn  
- Random Forest  
- LIME  
- SHAP  
- Matplotlib / Seaborn  
- Pandas / NumPy

---

## üìÇ Estructura de Archivos

```bash
 proyecto3/               
   ‚îú‚îÄ üìú README.md              ‚Üê Carpeta del Proyecto 3
   ‚îú‚îÄ üìÇ data/                 
   ‚îú‚îÄ üìî notebooks/             
   ‚îú‚îÄ üìÇ scripts/               
   ‚îú‚îÄ üìÇ reports/              
   ‚îî‚îÄ üìú requirements.txt       
  ```
--- 

## üìà Resultados Principales/Hallazgos

El an√°lisis de un modelo de Random Forest para predecir enfermedades card√≠acas present√≥ el siguiente resultado:

<p align="center">
  <img src="img/Metricas.png" width="45.7%" />
  <img src="img/F1-Score.png" width="45%" />
</p>

<h3 align="center">Modelo Random Forest entrenado</h3>
<h4 align="center">M√©tricas en entrenamiento: <b>accuracy: 1.00</b></h4>

<table align="center">
  <thead>
    <tr>
      <th>Clase del paciente</th>
      <th>Precisi√≥n</th>
      <th>Recall</th>
      <th>F1-Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Sano (0)</td>
      <td align="right">1.00</td>
      <td align="right">1.00</td>
      <td align="right">1.00</td>
    </tr>
    <tr>
      <td>Enfermo (1)</td>
      <td align="right">1.00</td>
      <td align="right">1.00</td>
      <td align="right">1.00</td>
    </tr>
  </tbody>
</table>

<h3 align="center">Modelo Random Forest entrenado</h3>
<h4 align="center">M√©tricas en prueba: <b>accuracy: 0.89</b></h4>

<table align="center">
  <thead>
    <tr>
      <th>Clase del paciente</th>
      <th>Precisi√≥n</th>
      <th>Recall</th>
      <th>F1-Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Sano (0)</td>
      <td align="right">0.89</td>
      <td align="right">0.85</td>
      <td align="right">0.87</td>
    </tr>
    <tr>
      <td>Enfermo (1)</td>
      <td align="right">0.89</td>
      <td align="right">0.91</td>
      <td align="right">0.90</td>
    </tr>
  </tbody>
</table>

y arroj√≥ la siguiente matriz de confusi√≥n:

<h3 align="center">üîπ Matriz de confusi√≥n ‚Äî Modelo Random Forest</h3>

<table align="center">
  <thead>
    <tr>
      <th>Real \ Predicci√≥n</th>
      <th>0 (Sano)</th>
      <th>1 (Enfermo)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><b>0 (Sano)</b></td>
      <td align="center">0.705</td>
      <td align="center">0.640</td>
    </tr>
    <tr>
      <td><b>1 (Enfermo)</b></td>
      <td align="center">0.780</td>
      <td align="center">0.640</td>
    </tr>
  </tbody>
</table>

Se tuvo que, el modelo Random Forest mostr√≥ un excelente desempe√±o, con un accuracy del 89% en prueba, aunque evidenci√≥ sobreajuste por su rendimiento perfecto en entrenamiento (100%). Detect√≥ eficazmente a los pacientes con enfermedad (recall = 0.91), pero a√∫n cometi√≥ algunos errores: 12 falsos positivos y 9 falsos negativos, siendo estos √∫ltimos cl√≠nicamente m√°s cr√≠ticos. En general, el modelo generaliz√≥ bien, pero requiere ajuste de hiperpar√°metros para reducir el sobreajuste y mejorar la detecci√≥n de casos verdaderamente enfermos.

Con las siguientes herramientas de interpretabilidad se revel√≥ que, aunque el modelo tiene una alta precisi√≥n general (88.6%), su l√≥gica interna es defectuosa y potencialmente peligrosa.

### Uso de herramientas de interpretabilidad: SHAP

### Explicabilidad de un caso (paciente) que el modelo predijo que padec√≠a de una enfermedad card√≠aca pero que en realidad estaba sano

<div align="center">
  <H3> SHAP </H3>
</div>
<p align="center">
  <img src="img/SHAP.png" width="60%" />
</p>

El modelo predijo un 83% de probabilidad de enfermedad card√≠aca para el paciente 50, aunque en realidad estaba sano (falso positivo). La predicci√≥n se vio influenciada principalmente por la ausencia de elevaci√≥n del segmento ST, un valor an√≥malo de colesterol = 0, y la presencia de angina durante el ejercicio, factores que el modelo interpret√≥ como se√±ales de alto riesgo. Esto evidenci√≥ que el modelo era sensible a datos err√≥neos y pod√≠a generar predicciones incorrectas cuando exist√≠an valores at√≠picos o inconsistentes, destacando la necesidad de mejorar la calidad de los datos y ajustar la interpretaci√≥n de variables cr√≠ticas.

### Uso de herramientas de interpretabilidad: LIME

<div align="center">
  <H3> LIME </H3>
</div>
<p align="center">
  <img src="img/LIME.png" width="80%" />
</p>

El modelo predijo err√≥neamente un 82% de probabilidad de enfermedad card√≠aca para el paciente 50, quien en realidad estaba sano (falso positivo). Factores como la ausencia de elevaci√≥n del segmento ST, la presencia de angina durante el ejercicio y un valor an√≥malo de colesterol = 0 influyeron decisivamente en la predicci√≥n. El an√°lisis LIME evidenci√≥ que el modelo malinterpret√≥ variables cl√≠nicas y valores an√≥malos, lo que destac√≥ la necesidad de mejorar la calidad de los datos y ajustar la interpretaci√≥n de factores cr√≠ticos para evitar errores similares en el futuro.

### Comparativa entre LIME Y SHAP en base a los resultados obtenidos

Tanto SHAP como LIME proporcionaron interpretabilidad del modelo, pero con enfoques distintos. Ambos explican predicciones individuales, identifican las variables m√°s influyentes (como ECG y angina) y presentan visualizaciones claras.

Diferencias clave:
	‚Ä¢	SHAP ofrece explicaciones locales y globales, es te√≥ricamente consistente (valores de Shapley) y permite detectar patrones y contradicciones en todo el modelo.
	‚Ä¢	LIME es estrictamente local, crea modelos simples alrededor de cada caso y depende de los datos cercanos para su precisi√≥n, sin ofrecer visi√≥n global.

En conclusi√≥n, SHAP es m√°s robusto y completo, mientras que LIME es √∫til para explicaciones r√°pidas de casos individuales; ambos son complementarios para entender y auditar el modelo.


## üìÑ Conclusiones

El modelo Random Forest mostr√≥ un alto rendimiento en prueba (accuracy 88.6%), apoy√°ndose en variables cl√≠nicamente relevantes como ST_Slope, angina por ejercicio y Oldpeak. Sin embargo, su l√≥gica present√≥ fallas cr√≠ticas: fue sensible a datos err√≥neos (valores an√≥malos de colesterol) y cometi√≥ falsos positivos y negativos, ignorando en algunos casos se√±ales cl√≠nicas importantes como angina o MaxHR.

Vimos casos puntuales, como el del paciente X, en donde analizamos la explicabilidad utilizando SHAP y LIME. En este caso, el modelo lo predijo como enfermo, aunque en realidad estaba sano, permiti√©ndonos identificar un falso positivo y las variables m√°s influyentes que llevaron a esa predicci√≥n err√≥nea.

Esto evidencia que alta precisi√≥n no garantiza confiabilidad y que la interpretabilidad es esencial para auditar la l√≥gica del modelo, aumentar la confianza de los m√©dicos e identificar sesgos. Para conocer los detalles completos de este an√°lisis y complementarlo con los resultados vistos aqu√≠, se recomienda revisar el notebook .ipynb, donde aparece el an√°lisis detallado.

Considerar que, a futuro, se planear√° una mejora del modelo, enfocada en depuraci√≥n y validaci√≥n exhaustiva de los datos, optimizaci√≥n de hiperpar√°metros, y evaluaci√≥n comparativa con algoritmos como XGBoost o redes neuronales. Adem√°s, se implementar√° un proceso continuo de monitorizaci√≥n y reentrenamiento con nuevos datos cl√≠nicos, garantizando un modelo m√°s robusto, confiable y alineado con la medicina basada en evidencia.

#### üîó [Ver an√°lisis completo en el Notebook (.ipynb) ¬ª](./notebooks/IMP_LIME_y_SHAP.ipynb)
